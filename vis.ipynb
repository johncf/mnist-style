{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a7f565-d801-4fc4-a2a3-22456c9b2e69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mnist_style.models import ClassifyingAutoEncoder\n",
    "from mnist_style.persistence import load_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf75b507-68c2-4e26-9d13-22771c3a48da",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from functools import partial\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694bb35a-62af-4890-a7ea-4ee04c1052a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_classes, style_dim = 10, 4\n",
    "autoencoder = ClassifyingAutoEncoder(n_classes, style_dim)\n",
    "\n",
    "load_models({\"encoder\": autoencoder.encoder, \"decoder\": autoencoder.decoder}, \"./pt-aae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69199a-1989-4f1c-b6e8-2cef86344b08",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_dataset = MNIST(root='./data', train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6f8bb-1cfb-4ffd-a078-b88f1b3d52c2",
   "metadata": {},
   "source": [
    "### Style Vector Distribution Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cdfc68-142e-4b12-9caa-8522a0ade26c",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=True)\n",
    "\n",
    "autoencoder.eval()\n",
    "for batch, labels in test_dataloader:\n",
    "    _, style_feats = autoencoder.forward_encoder(batch)\n",
    "    features = style_feats.detach().numpy()\n",
    "    columns = ['f' + chr(i + ord('a')) for i in range(features.shape[1])]\n",
    "    df = pd.DataFrame(features, columns=columns)\n",
    "    df = df.assign(digit=labels)\n",
    "    g = sns.pairplot(df, hue=\"digit\", palette=\"tab10\")  # hls\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf67737-a586-4ec1-b6c2-d9d0d2bcb814",
   "metadata": {},
   "source": [
    "### Compare Random Dataset Images and Corresponding AutoEncoder Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d110eb-723d-4103-b927-e04f6558e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "autoencoder.eval()\n",
    "fig, axs = plt.subplots(2, 10, figsize=(16, 3))\n",
    "for batch, _ in test_dataloader:\n",
    "    class_logits, style_feats, decoded_batch = autoencoder(batch)\n",
    "\n",
    "    vals, idxs = F.softmax(class_logits.detach(), dim=1).max(dim=1)\n",
    "    print(list(zip(idxs.tolist(), vals.numpy().round(3))))\n",
    "\n",
    "    for i, (image, decoded) in enumerate(zip(batch, decoded_batch.detach())):\n",
    "        axs[0, i].set_axis_off()\n",
    "        axs[1, i].set_axis_off()\n",
    "        axs[0, i].imshow(image[0], cmap=\"viridis\")\n",
    "        axs[1, i].imshow(decoded[0], cmap=\"viridis\")\n",
    "    break\n",
    "fig.tight_layout(pad=0, h_pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30583dc-93f7-4a6e-9bfe-c7797f3a312c",
   "metadata": {},
   "source": [
    "### Classifier Accuracy and Style Vector Distribution Fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587acd74-7a14-407c-89d3-71bedfa020f5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=400, shuffle=True)\n",
    "\n",
    "feat_names = ['feat ' + chr(ord('a') + i) for i in range(style_dim)]\n",
    "batch_dfs = []\n",
    "\n",
    "autoencoder.eval()\n",
    "for batch, labels in test_dataloader:\n",
    "    class_logits, style_feats = autoencoder.forward_encoder(batch)\n",
    "    features = style_feats.detach().numpy()\n",
    "    df = pd.DataFrame(features, columns=feat_names)\n",
    "    df['digit'] = labels.numpy()\n",
    "    predicted = np.argmax(class_logits.detach().numpy(), axis=1)\n",
    "    df['accuracy'] = labels.numpy() == predicted\n",
    "    batch_dfs.append(df)\n",
    "\n",
    "df = pd.concat(batch_dfs)\n",
    "print('mean accuracy:', np.mean(df['accuracy']))\n",
    "df[['digit', 'accuracy']].groupby('digit').mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0ef7d-d766-424d-a9f9-bc061b821cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodness_of_fit_metric(samples, norm_scale=2):\n",
    "    cdf = partial(stats.norm.cdf, loc=0, scale=norm_scale)\n",
    "    ks_test = stats.ks_1samp(samples, cdf)\n",
    "    return -np.log10(ks_test.pvalue)  # ks_test.statistic\n",
    "\n",
    "all_goodness = goodness_of_fit_metric(df[feat_names].values.ravel())\n",
    "feat_wise_logps = [[all_goodness] + [goodness_of_fit_metric(df[feat]) for feat in feat_names]]\n",
    "for digit in range(10):\n",
    "    df_dig = df.query(f'digit == {digit}')\n",
    "    all_feat_goodness = goodness_of_fit_metric(df_dig[feat_names].values.ravel())\n",
    "    feat_wise_logps.append([all_feat_goodness] + [goodness_of_fit_metric(df_dig[feat]) for feat in feat_names])\n",
    "pd.DataFrame(feat_wise_logps, columns=['all features'] + feat_names, index=['all digits'] + [f'digit {i}' for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0f7d9-d4e1-45e9-8e8d-da4c6630d10e",
   "metadata": {},
   "source": [
    "### Generate New Images for Random Style Vectors (fixed per row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d1a4f2-f843-41e8-a586-518170b98c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "fig, axs = plt.subplots(4, 10, figsize=(16, 6.35))\n",
    "for i in range(4):\n",
    "    classes_batch = np.zeros((10, n_classes), dtype=np.float32)\n",
    "    classes_batch[range(10), range(10)] = 1.\n",
    "    style_batch = np.random.normal(loc=0, scale=1, size=(10, 4)).astype(np.float32)\n",
    "    encoded_batch = np.concatenate((classes_batch, style_batch), axis=1)\n",
    "    decoded_batch = autoencoder.decoder(torch.tensor(encoded_batch))\n",
    "\n",
    "    for j, decoded in enumerate(decoded_batch.detach()):\n",
    "        axs[i, j].set_axis_off()\n",
    "        axs[i, j].imshow(decoded[0], cmap=\"viridis\")\n",
    "fig.tight_layout(pad=0, h_pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f78dbd-aa45-4716-8b1b-df3251fdc8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
