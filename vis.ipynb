{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a7f565-d801-4fc4-a2a3-22456c9b2e69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from mnist_style.models import ClassifyingAutoEncoder\n",
    "from mnist_style.persistence import load_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf75b507-68c2-4e26-9d13-22771c3a48da",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from functools import partial\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694bb35a-62af-4890-a7ea-4ee04c1052a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_classes, style_dim = 10, 4\n",
    "autoencoder = ClassifyingAutoEncoder(n_classes, style_dim)\n",
    "\n",
    "load_models({\"encoder\": autoencoder.encoder, \"decoder\": autoencoder.decoder}, \"./pt-aae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69199a-1989-4f1c-b6e8-2cef86344b08",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_dataset = MNIST(root='./data', train=False, download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e6f8bb-1cfb-4ffd-a078-b88f1b3d52c2",
   "metadata": {},
   "source": [
    "### Style Vector Distribution Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea68b3-9b96-450b-bf97-e6571020f123",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "feat_names = ['feat_' + chr(ord('a') + i) for i in range(style_dim)]\n",
    "test_enc_dfs = []\n",
    "autoencoder.eval()\n",
    "with torch.inference_mode():\n",
    "    for batch, labels in test_dataloader:\n",
    "        class_logits, style_feats = autoencoder.forward_encoder(batch)\n",
    "        features = style_feats.detach().numpy()\n",
    "        predictions = np.argmax(class_logits.detach().numpy(), axis=1)\n",
    "        df = pd.DataFrame(features, columns=feat_names)\n",
    "        df['digit'] = labels.numpy()\n",
    "        df['prediction'] = predictions\n",
    "        test_enc_dfs.append(df)\n",
    "encoder_df = pd.concat(test_enc_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602201d7-cdce-40e0-afed-4c82e99cc49b",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = sns.PairGrid(encoder_df, hue=\"digit\", diag_sharey=False, height=3, palette=\"tab10\")  # hue=\"hls\"\n",
    "g.map_diag(sns.histplot, multiple=\"stack\", element=\"bars\")\n",
    "g.map_offdiag(sns.scatterplot)\n",
    "g.add_legend()\n",
    "for i, axs in enumerate(g.axes):\n",
    "    for j, ax in enumerate(axs):\n",
    "        ax.axvline(color='black', linewidth=0.5)\n",
    "        if i != j:\n",
    "            ax.axhline(color='black', linewidth=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf67737-a586-4ec1-b6c2-d9d0d2bcb814",
   "metadata": {},
   "source": [
    "### Compare Random Dataset Images and Corresponding AutoEncoder Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d110eb-723d-4103-b927-e04f6558e10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_per_row = 10\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=imgs_per_row, shuffle=True)\n",
    "\n",
    "autoencoder.eval()\n",
    "fig, axs = plt.subplots(2, imgs_per_row, figsize=(16, 3))\n",
    "for batch, _ in test_dataloader:\n",
    "    class_logits, style_feats, decoded_batch = autoencoder(batch)\n",
    "\n",
    "    vals, idxs = F.softmax(class_logits.detach(), dim=1).max(dim=1)\n",
    "    print(list(zip(idxs.tolist(), vals.numpy().round(3))))\n",
    "\n",
    "    for i, (image, decoded) in enumerate(zip(batch, decoded_batch.detach())):\n",
    "        axs[0, i].set_axis_off()\n",
    "        axs[1, i].set_axis_off()\n",
    "        axs[0, i].imshow(image[0], cmap=\"viridis\")\n",
    "        axs[1, i].imshow(decoded[0], cmap=\"viridis\")\n",
    "    break\n",
    "fig.tight_layout(pad=0, h_pad=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30583dc-93f7-4a6e-9bfe-c7797f3a312c",
   "metadata": {},
   "source": [
    "### Classifier Accuracy and Style Vector Distribution Fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587acd74-7a14-407c-89d3-71bedfa020f5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_dataset, batch_size=400, shuffle=True)\n",
    "\n",
    "enc_acc_df = encoder_df.assign(accuracy=encoder_df['digit'] == encoder_df['prediction'])\n",
    "print('mean accuracy:', np.mean(enc_acc_df['accuracy']))\n",
    "enc_acc_df[['digit', 'accuracy']].groupby('digit').mean().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0ef7d-d766-424d-a9f9-bc061b821cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def goodness_of_fit_metric(samples, norm_scale=2):\n",
    "    cdf = partial(stats.norm.cdf, loc=0, scale=norm_scale)\n",
    "    ks_test = stats.ks_1samp(samples, cdf)\n",
    "    return -np.log10(ks_test.pvalue) if ks_test.pvalue > 0 else np.inf\n",
    "    # return ks_test.statistic\n",
    "\n",
    "all_goodness = goodness_of_fit_metric(encoder_df[feat_names].values.ravel())\n",
    "feat_wise_logps = [[all_goodness] + [goodness_of_fit_metric(encoder_df[feat]) for feat in feat_names]]\n",
    "for digit in range(10):\n",
    "    df_dig = encoder_df.query(f'digit == {digit}')\n",
    "    all_feat_goodness = goodness_of_fit_metric(df_dig[feat_names].values.ravel())\n",
    "    feat_wise_logps.append([all_feat_goodness] + [goodness_of_fit_metric(df_dig[feat]) for feat in feat_names])\n",
    "pd.DataFrame(feat_wise_logps, columns=['all features'] + feat_names, index=['all digits'] + [f'digit {i}' for i in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f0f7d9-d4e1-45e9-8e8d-da4c6630d10e",
   "metadata": {},
   "source": [
    "### Generate New Images for Random Style Vectors (fixed per row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d1a4f2-f843-41e8-a586-518170b98c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 3\n",
    "norm_scale = 1\n",
    "autoencoder.eval()\n",
    "fig, axs = plt.subplots(num_rows, 10, figsize=(16, 4.75))\n",
    "for i in range(num_rows):\n",
    "    classes_onehot = F.one_hot(torch.arange(10), 10)\n",
    "    style_feats = torch.randn((10, style_dim), dtype=torch.float32) * norm_scale\n",
    "    encoded_batch = torch.concat((classes_onehot, style_feats), dim=1)\n",
    "    decoded_batch = autoencoder.decoder(encoded_batch)\n",
    "\n",
    "    for j, decoded in enumerate(decoded_batch.detach()):\n",
    "        axs[i, j].set_axis_off()\n",
    "        axs[i, j].imshow(decoded[0], cmap=\"viridis\")\n",
    "fig.tight_layout(pad=0, h_pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f78dbd-aa45-4716-8b1b-df3251fdc8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
